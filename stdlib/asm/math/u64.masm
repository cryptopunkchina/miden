# ===== HELPER FUNCTIONS ======================================================================== #

# Asserts that both values at the top of the stack are u64 values. #
# The input values are assumed to be represented using 32 bit limbs, fails if they are not. #
proc.u64assert4
    u32assert
    movup.3
    u32assert
    movup.3
    u32assert
    movup.3
    u32assert
    movup.3
end

# ===== ADDITION ================================================================================ #

# Performs addition of two unsigned 64 bit integers discarding the overflow. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = (a + b) % 2^64 #
export.add_unsafe
    swap
    movup.3
    u32add.unsafe
    movup.3
    movup.3
    u32addc.unsafe
    drop
end

# ===== SUBTRACTION ============================================================================= #

# Performs subtraction of two unsigned 64 bit integers discarding the overflow. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = (a - b) % 2^64 #
export.sub_unsafe
    movup.3
    movup.2
    u32sub.unsafe
    movup.3
    movup.3
    u32sub.unsafe
    drop
    swap
    u32sub.unsafe
    drop
end

# ===== MULTIPLICATION ========================================================================== #

# Performs multiplication of two unsigned 64 bit integers discarding the overflow. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = (a * b) % 2^64 #
export.mul_unsafe
    dup.3
    dup.2
    u32mul.unsafe
    movup.4
    movup.4
    u32madd.unsafe
    drop
    movup.3
    movup.3
    u32madd.unsafe
    drop
end

# ===== COMPARISONS ============================================================================= #

# Performs less-than comparison of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c, ...], where c = 1 when a < b, and 0 otherwise. #
export.lt_unsafe
    movup.3
    movup.2
    u32sub.unsafe
    movdn.3
    drop
    u32sub.unsafe
    swap
    eq.0
    movup.2
    and
    or
end

# Performs greater-than comparison of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c, ...], where c = 1 when a > b, and 0 otherwise. #
export.gt_unsafe
    movup.2
    u32sub.unsafe
    movup.2
    movup.3
    u32sub.unsafe
    swap
    drop
    movup.2
    eq.0
    and
    or
end

# Performs less-than-or-equal comparison of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c, ...], where c = 1 when a <= b, and 0 otherwise. #
export.lte_unsafe
    exec.gt_unsafe
    not
end

# Performs greater-than-or-equal comparison of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c, ...], where c = 1 when a >= b, and 0 otherwise. #
export.gte_unsafe
    exec.lt_unsafe
    not
end

# Performs equality comparison of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c, ...], where c = 1 when a == b, and 0 otherwise. #
export.eq_unsafe
    movup.2
    u32eq
    swap
    movup.2
    u32eq
    and
end

# Performs comparison to zero of an unsigned 64 bit integer. #
# The input value is assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [a_hi, a_lo, ...] -> [c, ...], where c = 1 when a == 0, and 0 otherwise. #
export.eqz_unsafe
    u32eq.0
    swap
    u32eq.0
    and
end

# ===== DIVISION ================================================================================ #

# Performs division of two unsigned 64 bit integers discarding the remainder. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a // b #
export.div_unsafe
    adv.u64div          # inject the quotient and the remainder into the advice tape #
    
    push.adv.1          # read the quotient from the advice tape and make sure it consists of #
    u32assert           # 32-bit limbs #
    push.adv.1          # TODO: this can be optimized once we have u32assert2 instruction #
    u32assert

    dup.3               # multiply quotient by the divisor and make sure the resulting value #
    dup.2               # fits into 2 32-bit limbs #
    u32mul.unsafe
    dup.4
    dup.4
    u32madd.unsafe
    eq.0
    assert
    dup.5
    dup.3
    u32madd.unsafe
    eq.0
    assert
    dup.4
    dup.3
    mul
    eq.0
    assert

    push.adv.1          # read the remainder from the advice tape and make sure it consists of #
    u32assert           # 32-bit limbs #
    push.adv.1
    u32assert

    movup.7             # make sure the divisor is greater than the remainder. this also consumes #
    movup.7             # the divisor #
    dup.3
    dup.3
    exec.gt_unsafe
    assert

    swap                # add remainder to the previous result; this also consumes the remainder #
    movup.3
    u32add.unsafe
    movup.3
    movup.3
    u32addc.unsafe
    eq.0
    assert

    movup.4             # make sure the result we got is equal to the dividend #
    assert.eq
    movup.3
    assert.eq           # quotient remains on the stack #
end

# ===== MODULO OPERATION ================================================================================ #

# Performs modulo operation of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, but this is not checked. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a % b #
export.mod_unsafe
    adv.u64div          # inject the quotient and the remainder into the advice tape #
    
    push.adv.1          # read the quotient from the advice tape and make sure it consists of #
    u32assert           # 32-bit limbs #
    push.adv.1          # TODO: this can be optimized once we have u32assert2 instruction #
    u32assert

    dup.3               # multiply quotient by the divisor and make sure the resulting value #
    dup.2               # fits into 2 32-bit limbs #
    u32mul.unsafe
    dup.4
    movup.4
    u32madd.unsafe
    eq.0
    assert
    dup.4
    dup.3
    u32madd.unsafe
    eq.0
    assert
    dup.3
    movup.3
    mul
    eq.0
    assert

    push.adv.1          # read the remainder from the advice tape and make sure it consists of #
    u32assert           # 32-bit limbs #
    push.adv.1
    u32assert

    movup.5             # make sure the divisor is greater than the remainder. this also consumes #
    movup.5             # the divisor #
    dup.3
    dup.3
    exec.gt_unsafe
    assert

    dup.1               # add remainder to the previous result #
    movup.4
    u32add.unsafe
    movup.4
    dup.3
    u32addc.unsafe
    eq.0
    assert

    movup.4             # make sure the result we got is equal to the dividend #
    assert.eq
    movup.3
    assert.eq           # remainder remains on the stack #
end

# ===== BITWISE OPERATIONS ====================================================================== #

# Performs bitwise AND of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, fails if they are not. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a AND b. #
export.and
    swap
    movup.3
    u32and
    swap
    movup.2
    u32and
end

# Performs bitwise OR of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, fails if they are not. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a OR b. #
export.or
    swap
    movup.3
    u32or
    swap
    movup.2
    u32or
end

# Performs bitwise XOR of two unsigned 64 bit integers. #
# The input values are assumed to be represented using 32 bit limbs, fails if they are not. #
# Stack transition looks as follows: #
# [b_hi, b_lo, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a XOR b. #
export.xor
    swap
    movup.3
    u32xor
    swap
    movup.2
    u32xor
end

# Performs left shift of one unsigned 64-bit integer using the pow2 operation. #
# The input value to be shifted is assumed to be represented using 32 bit limbs. #
# The shift value is assumed to be in the range [0, 64). #
# Stack transition looks as follows: #
# [b, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a << b mod 2^64. #
# This takes 13 cycles. #
export.shl
    pow2
    u32split
    exec.mul_unsafe
end

# Performs right shift of one unsigned 64-bit integer using the pow2 operation. #
# The input value to be shifted is assumed to be represented using 32 bit limbs. #
# The shift value is assumed to be in the range [0, 64). #
# Stack transition looks as follows: #
# [b, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a >> b. #
# This takes 29 cycles. #
export.shr
    pow2
    u32split
    
    dup.1
    add
    movup.2
    swap
    u32div.unsafe
    movup.3
    movup.3
    dup
    eq.0
    u32sub.unsafe
    not
    movdn.4
    dup
    movdn.4
    u32div.unsafe
    drop
    push.4294967296
    dup.5
    mul
    movup.4
    div
    movup.2
    mul
    add
    movup.2
    cswap
end

# Performs left rotation of one unsigned 64-bit integer using the pow2 operation. #
# The input value to be shifted is assumed to be represented using 32 bit limbs. #
# The shift value is assumed to be in the range [0, 64). #
# Stack transition looks as follows: #
# [b, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a << b mod 2^64. #
# This takes 20 cycles. #
export.rotl
    push.31
    dup.1
    u32sub.unsafe
    swap
    drop
    movdn.3
    
    # Shift the low limb. #
    push.31
    u32and
    pow2
    dup
    movup.3
    u32mul.unsafe

    # Shift the high limb. #
    movup.3
    movup.3
    u32madd.unsafe

    # Carry the overflow shift to the low bits. #
    movup.2
    add
    swap

    # Conditionally select the limb order based on whether it's shifting by > 31 or not. #
    movup.2
    cswap
end

# Performs right rotation of one unsigned 64-bit integer using the pow2 operation. #
# The input value to be shifted is assumed to be represented using 32 bit limbs. #
# The shift value is assumed to be in the range [0, 64). #
# Stack transition looks as follows: #
# [b, a_hi, a_lo, ...] -> [c_hi, c_lo, ...], where c = a << b mod 2^64. #
# This takes 25 cycles. #
export.rotr
    push.31
    dup.1
    u32sub.unsafe
    swap
    drop
    movdn.3
    
    # Shift the low limb left by 32-b. #
    push.31
    u32and
    push.32
    swap
    u32sub.unsafe
    drop
    pow2
    dup
    movup.3
    u32mul.unsafe

    # Shift the high limb left by 32-b. #
    movup.3
    movup.3
    u32madd.unsafe

    # Carry the overflow shift to the low bits. #
    movup.2
    add
    swap

    # Conditionally select the limb order based on whether it's shifting by > 31 or not. #
    movup.2
    not
    cswap
end
